defaults:
  - _self_
  - search_space: hpo_rl_bench_ppo
  - override hydra/sweeper: HyperCARPS

algorithm: PPO
environment: Pong-v0
metric_key: "eval_avg_returns"
seed: 0
budget: 50
hp_config: 
  lr: -6
  gamma: 0.8
  clip: 0.2

hydra:
  sweeper:
    n_trials: 30
    search_space: ${search_space}
    budget_variable: budget
    sweeper_kwargs:
      maximize: true
      optimizer_kwargs:
        _target_: carps.optimizers.smac20.SMAC3Optimizer
        _partial_: true
        task: 
          n_trials: ${hydra.sweeper.n_trials}
          n_objectives: 1
          time_budget: null
          n_workers: 1
          is_multifidelity: false
          min_budget: 1
          max_budget: 50
        smac_cfg:
          smac_class: smac.facade.multi_fidelity_facade.MultiFidelityFacade
          scenario:
            seed: 0
            n_trials: ${hydra.sweeper.n_trials}
            deterministic: true
            n_workers: 1
            min_budget: 1
            max_budget: 50
            output_directory: ${hydra.sweep.dir}
          smac_kwargs:
            dask_client: null
            intensifier:
              _target_: smac.intensifier.hyperband.Hyperband
              _partial_: true
              eta: 3
  run:
    dir: ./results/hpo_rl_bench/${algorithm}_${environment}_smac/
  sweep:
    dir: ./results/hpo_rl_bench/${algorithm}_${environment}_smac/