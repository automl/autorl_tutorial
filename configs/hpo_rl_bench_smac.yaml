defaults:
  - _self_
  - search_space: hpo_rl_bench_ppo
  - override hydra/sweeper: HyperSMAC

algorithm: PPO
env: Pong-v0
metric_key: "eval_avg_returns"
seed: 0
budget: 50
hp_config: 
  lr: -6
  gamma: 0.8
  clip: 0.2

hydra:
  sweeper:
    n_trials: 30
    budget_variable: budget
    sweeper_kwargs:
      optimizer_kwargs:
        smac_facade: 
          _target_: smac.facade.multi_fidelity_facade.MultiFidelityFacade
          _partial_: true
        intensifier: 
          _target_: smac.facade.multi_fidelity_facade.MultiFidelityFacade.get_intensifier
          _partial_: true
          eta: 3
        scenario:
          n_trials: ${hydra.sweeper.n_trials}
          seed: ${seed}
          min_budget: 1
          max_budget: 50
          deterministic: true
          n_workers: 1
          output_directory: ${hydra.sweep.dir}
    search_space: ${search_space}
  run:
    dir: ./results/hpo_rl_bench/${algorithm}_${env}_smac/
  sweep:
    dir: ./results/hpo_rl_bench/${algorithm}_${env}_smac/